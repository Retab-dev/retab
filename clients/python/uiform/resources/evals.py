from typing import Any, Dict, List, Optional, Union, TypedDict

from .._resource import AsyncAPIResource, SyncAPIResource
from ..types.standards import PreparedRequest


import copy
import datetime
import json
from typing import Any, List, Literal, Optional, Union

import nanoid  # type: ignore
from pydantic import BaseModel, Field, computed_field

from .._utils.json_schema import clean_schema
from .._utils.mime import generate_blake2b_hash_from_string
from ..types.ai_models import Amount, LLMModel
from ..types.jobs.base import AnnotationProps
from ..types.mime import BaseMIMEData, MIMEData

ScalarDistanceMetric = Literal["levenstein", "hamming", "jaccard"]
# Define the type alias for MetricType
MetricType = Literal["levenshtein", "jaccard", "hamming"]


class LLMDistanceMetric(BaseModel):
    name: str
    description: str
    instructions: list[MIMEData]  # Or list[str], where each str is generated by the LLM, a little paragraph summarizing the instructions ?


# Define the structure for an individual item metric
class ItemMetric(BaseModel):
    id: str = Field(description="The ID of the item being measured")
    name: str = Field(description="The name of the item being measured")
    similarity: float = Field(description="The similarity score between 0 and 1")
    similarities: dict[str, Any] = Field(description="The similarity scores for each item in the list")
    flat_similarities: dict[str, Optional[float]] = Field(description="The similarity scores for each item in the list in dot notation format")


# Define the main MetricResult model
class MetricResult(BaseModel):
    item_metrics: List[ItemMetric] = Field(description="List of similarity metrics for individual items")
    mean_similarity: float = Field(description="The average similarity score across all items")
    metric_type: MetricType = Field(description="The type of similarity metric used for comparison")


class AnnotationData(BaseModel):
    annotation: dict[str, Any] = Field(default={}, description="The result of the extraction or manual annotation")
    likelihoods: Optional[dict[str, Any]] = Field(default=None, description="The likelihoods of the extraction")
    field_locations: Optional[dict[str, Any]] = Field(default=None, description="The field locations of the extraction")
    consensus_details: Optional[list[dict[str, Any]]] = Field(default=None, description="The consensus details of the extraction")
    api_cost: Optional[Amount] = Field(default=None, description="The cost of the API call for this document (if any -- ground truth for example)")


class Iteration(BaseModel):
    id: str = Field(default_factory=lambda: "expit_" + nanoid.generate())
    annotation_props: AnnotationProps
    json_schema: dict[str, Any]
    annotations: list[AnnotationData] = Field(default_factory=list, description="The annotations of the iteration")

    @computed_field  # type: ignore
    @property
    def schema_data_id(self) -> str:
        """Returns the SHA1 hash of the schema data, ignoring all prompt/description/default fields.

        Returns:
            str: A SHA1 hash string representing the schema data version.
        """
        return "sch_data_id_" + generate_blake2b_hash_from_string(
            json.dumps(
                clean_schema(
                    copy.deepcopy(self.json_schema),
                    remove_custom_fields=True,
                    fields_to_remove=["description", "default", "title", "required", "examples", "deprecated", "readOnly", "writeOnly"],
                ),
                sort_keys=True,
            ).strip()
        )

    # This is a computed field, it is exposed when serializing the object
    @computed_field  # type: ignore
    @property
    def schema_id(self) -> str:
        """Returns the SHA1 hash of the complete schema.

        Returns:
            str: A SHA1 hash string representing the complete schema version.
        """
        return "sch_id_" + generate_blake2b_hash_from_string(json.dumps(self.json_schema, sort_keys=True).strip())


class DocumentItem(BaseModel):
    mime_data: MIMEData  # Can also be a BaseMIMEData, which is why we have this id field (to be able to identify the file, but id is equal to mime_data.id)
    ground_truth: AnnotationData = Field(default=AnnotationData(), description="The ground truth of the document")


class ExperimentDocument(DocumentItem):
    id: str = Field(description="The ID of the document. Equal to mime_data.id but robust to the case where mime_data is a BaseMIMEData")


class UpdateExperimentRequest(BaseModel):
    name: Optional[str] = Field(default=None, description="The name of the document")
    documents: Optional[list[ExperimentDocument]] = Field(default=None, description="The documents of the experiment")
    iterations: Optional[list[Iteration]] = Field(default=None, description="The iterations of the experiment")
    json_schema: Optional[dict[str, Any]] = Field(default=None, description="The json schema of the experiment")

    project_id: Optional[str] = Field(default=None, description="The ID of the project")

    @computed_field  # type: ignore
    @property
    def schema_data_id(self) -> Optional[str]:
        """Returns the SHA1 hash of the schema data, ignoring all prompt/description/default fields.

        Returns:
            str: A SHA1 hash string representing the schema data version.
        """
        if self.json_schema is None:
            return None

        return "sch_data_id_" + generate_blake2b_hash_from_string(
            json.dumps(
                clean_schema(
                    copy.deepcopy(self.json_schema),
                    remove_custom_fields=True,
                    fields_to_remove=["description", "default", "title", "required", "examples", "deprecated", "readOnly", "writeOnly"],
                ),
                sort_keys=True,
            ).strip()
        )

    # This is a computed field, it is exposed when serializing the object
    @computed_field  # type: ignore
    @property
    def schema_id(self) -> Optional[str]:
        """Returns the SHA1 hash of the complete schema.

        Returns:
            str: A SHA1 hash string representing the complete schema version.
        """
        if self.json_schema is None:
            return None
        return "sch_id_" + generate_blake2b_hash_from_string(json.dumps(self.json_schema, sort_keys=True).strip())


class Experiment(BaseModel):
    id: str = Field(default_factory=lambda: "exp_" + nanoid.generate())
    updated_at: datetime.datetime = Field(default_factory=lambda: datetime.datetime.now(tz=datetime.timezone.utc))

    name: str
    documents: list[ExperimentDocument]
    iterations: list[Iteration]
    json_schema: dict[str, Any]

    project_id: str = Field(description="The ID of the project", default="default_spreadsheets")
    default_annotation_props: Optional[AnnotationProps] = Field(default=None, description="The default annotation properties for the experiment (mostly used in the frontend)")

    # @field_validator('iterations')
    # def validate_iterations_content_length(cls: Any, v: list[Iteration], values: Any) -> list[Iteration]:
    #     if 'ground_truth' in values:
    #         ground_truth_length = len(values['ground_truth'])
    #         for iteration in v:
    #             if len(iteration.content) != ground_truth_length:
    #                 raise ValueError(f"Iteration content length must match ground_truth length ({ground_truth_length})")
    #     return v

    @computed_field  # type: ignore
    @property
    def schema_data_id(self) -> str:
        """Returns the SHA1 hash of the schema data, ignoring all prompt/description/default fields.

        Returns:
            str: A SHA1 hash string representing the schema data version.
        """
        return "sch_data_id_" + generate_blake2b_hash_from_string(
            json.dumps(
                clean_schema(
                    copy.deepcopy(self.json_schema),
                    remove_custom_fields=True,
                    fields_to_remove=["description", "default", "title", "required", "examples", "deprecated", "readOnly", "writeOnly"],
                ),
                sort_keys=True,
            ).strip()
        )

    # This is a computed field, it is exposed when serializing the object
    @computed_field  # type: ignore
    @property
    def schema_id(self) -> str:
        """Returns the SHA1 hash of the complete schema.

        Returns:
            str: A SHA1 hash string representing the complete schema version.
        """
        return "sch_id_" + generate_blake2b_hash_from_string(json.dumps(self.json_schema, sort_keys=True).strip())


class StoredExperiment(Experiment):
    organization_id: str


class CriticApplierIterationRequest(BaseModel):
    experiment: Experiment
    student_model: str
    critic_applier_model: str
    reference_iteration_index: int


class CriticApplierProposeJsonSchemaRequest(BaseModel):
    reference_iteration_index: int = -1
    iterator_model: LLMModel | str = "gpt-4o"


class CriticApplierProposeJsonSchemaResponse(BaseModel):
    json_schema: dict[str, Any]


class EvalsMixin:
    def prepare_create(self, name: str, json_schema: Dict[str, Any], project_id: str) -> PreparedRequest:
        return PreparedRequest(
            method="POST",
            url="/v1/experiments",
            data={
                "name": name,
                "json_schema": json_schema,
                "project_id": project_id,
                "documents": [],
                "iterations": []
            }
        )

    def prepare_get(self, id: str) -> PreparedRequest:
        return PreparedRequest(
            method="GET",
            url=f"/v1/experiments/{id}"
        )

    def prepare_update(self, id: str, name: str) -> PreparedRequest:
        return PreparedRequest(
            method="PUT",
            url=f"/v1/experiments/{id}",
            data={"name": name}
        )

    def prepare_list(self, project_id: str) -> PreparedRequest:
        return PreparedRequest(
            method="GET",
            url="/v1/experiments",
            params={"project_id": project_id}
        )

    def prepare_delete(self, id: str) -> PreparedRequest:
        return PreparedRequest(
            method="DELETE",
            url=f"/v1/experiments/{id}"
        )


class DocumentsMixin:
    def prepare_import_jsonl(self, eval_id: str, path: str) -> PreparedRequest:
        # This would be implemented based on the actual API endpoint
        return PreparedRequest(
            method="POST",
            url=f"/v1/experiments/{eval_id}/import_documents",
            data={"path": path}
        )

    def prepare_save_to_jsonl(self, eval_id: str, path: str) -> PreparedRequest:
        # This would be implemented based on the actual API endpoint
        return PreparedRequest(
            method="POST",
            url=f"/v1/experiments/{eval_id}/export_documents",
            data={"path": path}
        )

    def prepare_create(self, eval_id: str, document: str, ground_truth: Dict[str, Any]) -> PreparedRequest:
        return PreparedRequest(
            method="POST",
            url=f"/v1/experiments/{eval_id}/documents",
            data={"document": document, "ground_truth": ground_truth}
        )

    def prepare_list(self, eval_id: str, filename: Optional[str] = None) -> PreparedRequest:
        params = {}
        if filename:
            params["filename"] = filename
        return PreparedRequest(
            method="GET",
            url=f"/v1/experiments/{eval_id}/documents",
            params=params
        )


class DocumentMixin:
    def prepare_update(self, eval_id: str, id: str, ground_truth: Dict[str, Any]) -> PreparedRequest:
        return PreparedRequest(
            method="PUT",
            url=f"/v1/experiments/{eval_id}/documents/{id}",
            data={"ground_truth": ground_truth}
        )

    def prepare_delete(self, eval_id: str, id: str) -> PreparedRequest:
        return PreparedRequest(
            method="DELETE",
            url=f"/v1/experiments/{eval_id}/documents/{id}"
        )


class IterationsMixin:
    def prepare_import_jsonl(self, eval_id: str, path: str) -> PreparedRequest:
        return PreparedRequest(
            method="POST",
            url=f"/v1/experiments/{eval_id}/add_iteration_from_jsonl",
            data={"jsonl_gcs_path": path}
        )

    def prepare_save_to_jsonl(self, eval_id: str, path: str) -> PreparedRequest:
        return PreparedRequest(
            method="POST",
            url=f"/v1/experiments/{eval_id}/export_iteration_as_jsonl/0",
            data={"path": path}
        )

    def prepare_get(self, id: str) -> PreparedRequest:
        return PreparedRequest(
            method="GET",
            url=f"/v1/iterations/{id}"
        )

    def prepare_list(self, eval_id: str, model: Optional[str] = None) -> PreparedRequest:
        params = {}
        if model:
            params["model"] = model
        return PreparedRequest(
            method="GET",
            url=f"/v1/experiments/{eval_id}/iterations",
            params=params
        )

    def prepare_create(self, eval_id: str, json_schema: Dict[str, Any], model: str, temperature: float = 0.0, image_settings: Optional[Dict[str, Any]] = None) -> PreparedRequest:
        data = {
            "json_schema": json_schema,
            "annotation_props": {
                "model": model,
                "temperature": temperature
            }
        }
        if image_settings:
            data["annotation_props"]["image_settings"] = image_settings
        return PreparedRequest(
            method="POST",
            url=f"/v1/experiments/{eval_id}/iterations",
            data=data
        )

    def prepare_update(self, iteration_id: str, json_schema: Dict[str, Any], model: str, temperature: float = 0.0, image_settings: Optional[Dict[str, Any]] = None) -> PreparedRequest:
        data = {
            "json_schema": json_schema,
            "annotation_props": {
                "model": model,
                "temperature": temperature
            }
        }
        if image_settings:
            data["annotation_props"]["image_settings"] = image_settings
        return PreparedRequest(
            method="PUT",
            url=f"/v1/iterations/{iteration_id}",
            data=data
        )

    def prepare_delete(self, id: str) -> PreparedRequest:
        return PreparedRequest(
            method="DELETE",
            url=f"/v1/iterations/{id}"
        )


class DistancesMixin:
    def prepare_get(self, iteration_id: str, document_id: str) -> PreparedRequest:
        return PreparedRequest(
            method="GET",
            url=f"/v1/iterations/{iteration_id}/distances/{document_id}"
        )


class DeleteResponse(TypedDict):
    """Response from a delete operation"""
    success: bool
    id: str

class ExportResponse(TypedDict):
    """Response from an export operation"""
    success: bool
    path: str


class Evals(SyncAPIResource, EvalsMixin):
    """Evals API wrapper"""

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.documents = Documents(self._client)
        self.document = Document(self._client)
        self.iterations = Iterations(self._client)

    def create(self, name: str, json_schema: Dict[str, Any], project_id: str) -> Experiment:
        """
        Create a new evaluation.

        Args:
            name: The name of the evaluation
            json_schema: The JSON schema for the evaluation
            project_id: The project ID to associate with the evaluation

        Returns:
            Experiment: The created evaluation
        Raises:
            HTTPException if the request fails
        """
        request = self.prepare_create(name, json_schema, project_id)
        response = self._client._prepared_request(request)
        return Experiment(**response)

    def get(self, id: str) -> Experiment:
        """
        Get an evaluation by ID.

        Args:
            id: The ID of the evaluation to retrieve

        Returns:
            Experiment: The evaluation
        Raises:
            HTTPException if the request fails
        """
        request = self.prepare_get(id)
        response = self._client._prepared_request(request)
        return Experiment(**response)

    def update(self, id: str, name: str) -> Experiment:
        """
        Update an evaluation.

        Args:
            id: The ID of the evaluation to update
            name: The new name for the evaluation

        Returns:
            Experiment: The updated evaluation
        Raises:
            HTTPException if the request fails
        """
        request = self.prepare_update(id, name)
        response = self._client._prepared_request(request)
        return Experiment(**response)

    def list(self, project_id: str) -> List[Experiment]:
        """
        List evaluations for a project.

        Args:
            project_id: The project ID to list evaluations for

        Returns:
            List[Experiment]: List of evaluations
        Raises:
            HTTPException if the request fails
        """
        request = self.prepare_list(project_id)
        response = self._client._prepared_request(request)
        return [Experiment(**item) for item in response.get("data", [])]

    def delete(self, id: str) -> DeleteResponse:
        """
        Delete an evaluation.

        Args:
            id: The ID of the evaluation to delete

        Returns:
            DeleteResponse: The response containing success status and ID
        Raises:
            HTTPException if the request fails
        """
        request = self.prepare_delete(id)
        return self._client._prepared_request(request)


class Documents(SyncAPIResource, DocumentsMixin):
    """Documents API wrapper for evaluations"""

    def import_jsonl(self, eval_id: str, path: str) -> Experiment:
        """
        Import documents from a JSONL file.

        Args:
            eval_id: The ID of the evaluation
            path: The path to the JSONL file

        Returns:
            Experiment: The updated experiment with imported documents
        Raises:
            HTTPException if the request fails
        """
        request = self.prepare_import_jsonl(eval_id, path)
        response = self._client._prepared_request(request)
        return Experiment(**response)

    def save_to_jsonl(self, eval_id: str, path: str) -> ExportResponse:
        """
        Save documents to a JSONL file.

        Args:
            eval_id: The ID of the evaluation
            path: The path to save the JSONL file

        Returns:
            ExportResponse: The response containing success status and path
        Raises:
            HTTPException if the request fails
        """
        request = self.prepare_save_to_jsonl(eval_id, path)
        return self._client._prepared_request(request)

    def create(self, eval_id: str, document: str, ground_truth: Dict[str, Any]) -> ExperimentDocument:
        """
        Create a document for an evaluation.

        Args:
            eval_id: The ID of the evaluation
            document: The document file path or content
            ground_truth: The ground truth for the document

        Returns:
            ExperimentDocument: The created document
        Raises:
            HTTPException if the request fails
        """
        request = self.prepare_create(eval_id, document, ground_truth)
        response = self._client._prepared_request(request)
        return ExperimentDocument(**response)

    def list(self, eval_id: str, filename: Optional[str] = None) -> List[ExperimentDocument]:
        """
        List documents for an evaluation.

        Args:
            eval_id: The ID of the evaluation
            filename: Optional filename to filter by

        Returns:
            List[ExperimentDocument]: List of documents
        Raises:
            HTTPException if the request fails
        """
        request = self.prepare_list(eval_id, filename)
        response = self._client._prepared_request(request)
        return [ExperimentDocument(**item) for item in response.get("data", [])]


class Document(SyncAPIResource, DocumentMixin):
    """Document API wrapper for individual document operations"""

    def update(self, eval_id: str, id: str, ground_truth: Dict[str, Any]) -> ExperimentDocument:
        """
        Update a document.

        Args:
            eval_id: The ID of the evaluation
            id: The ID of the document
            ground_truth: The ground truth for the document

        Returns:
            ExperimentDocument: The updated document
        Raises:
            HTTPException if the request fails
        """
        request = self.prepare_update(eval_id, id, ground_truth)
        response = self._client._prepared_request(request)
        return ExperimentDocument(**response)

    def delete(self, eval_id: str, id: str) -> DeleteResponse:
        """
        Delete a document.

        Args:
            eval_id: The ID of the evaluation
            id: The ID of the document

        Returns:
            DeleteResponse: The response containing success status and ID
        Raises:
            HTTPException if the request fails
        """
        request = self.prepare_delete(eval_id, id)
        return self._client._prepared_request(request)


class Iterations(SyncAPIResource, IterationsMixin):
    """Iterations API wrapper for evaluations"""

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.distances = Distances(self._client)

    def import_jsonl(self, eval_id: str, path: str) -> Experiment:
        """
        Import iterations from a JSONL file.

        Args:
            eval_id: The ID of the evaluation
            path: The path to the JSONL file

        Returns:
            Experiment: The updated experiment with imported iterations
        Raises:
            HTTPException if the request fails
        """
        request = self.prepare_import_jsonl(eval_id, path)
        response = self._client._prepared_request(request)
        return Experiment(**response)

    def save_to_jsonl(self, eval_id: str, path: str) -> ExportResponse:
        """
        Save iterations to a JSONL file.

        Args:
            eval_id: The ID of the evaluation
            path: The path to save the JSONL file

        Returns:
            ExportResponse: The response containing success status and path
        Raises:
            HTTPException if the request fails
        """
        request = self.prepare_save_to_jsonl(eval_id, path)
        return self._client._prepared_request(request)

    def get(self, id: str) -> Iteration:
        """
        Get an iteration by ID.

        Args:
            id: The ID of the iteration

        Returns:
            Iteration: The iteration
        Raises:
            HTTPException if the request fails
        """
        request = self.prepare_get(id)
        response = self._client._prepared_request(request)
        return Iteration(**response)

    def list(self, eval_id: str, model: Optional[str] = None) -> List[Iteration]:
        """
        List iterations for an evaluation.

        Args:
            eval_id: The ID of the evaluation
            model: Optional model to filter by

        Returns:
            List[Iteration]: List of iterations
        Raises:
            HTTPException if the request fails
        """
        request = self.prepare_list(eval_id, model)
        response = self._client._prepared_request(request)
        return [Iteration(**item) for item in response.get("data", [])]

    def create(self, eval_id: str, json_schema: Dict[str, Any], model: str, temperature: float = 0.0, image_settings: Optional[Dict[str, Any]] = None) -> Iteration:
        """
        Create a new iteration for an evaluation.

        Args:
            eval_id: The ID of the evaluation
            json_schema: The JSON schema for the iteration
            model: The model to use for the iteration
            temperature: The temperature to use for the model
            image_settings: Optional image settings

        Returns:
            Iteration: The created iteration
        Raises:
            HTTPException if the request fails
        """
        request = self.prepare_create(eval_id, json_schema, model, temperature, image_settings)
        response = self._client._prepared_request(request)
        return Iteration(**response)

    def update(self, iteration_id: str, json_schema: Dict[str, Any], model: str, temperature: float = 0.0, image_settings: Optional[Dict[str, Any]] = None) -> Iteration:
        """
        Update an iteration.

        Args:
            iteration_id: The ID of the iteration
            json_schema: The JSON schema for the iteration
            model: The model to use for the iteration
            temperature: The temperature to use for the model
            image_settings: Optional image settings

        Returns:
            Iteration: The updated iteration
        Raises:
            HTTPException if the request fails
        """
        request = self.prepare_update(iteration_id, json_schema, model, temperature, image_settings)
        response = self._client._prepared_request(request)
        return Iteration(**response)

    def delete(self, id: str) -> DeleteResponse:
        """
        Delete an iteration.

        Args:
            id: The ID of the iteration

        Returns:
            DeleteResponse: The response containing success status and ID
        Raises:
            HTTPException if the request fails
        """
        request = self.prepare_delete(id)
        return self._client._prepared_request(request)


class Distances(SyncAPIResource, DistancesMixin):
    """Distances API wrapper for iterations"""

    def get(self, iteration_id: str, document_id: str) -> MetricResult:
        """
        Get distances for a document in an iteration.

        Args:
            iteration_id: The ID of the iteration
            document_id: The ID of the document

        Returns:
            MetricResult: The distances
        Raises:
            HTTPException if the request fails
        """
        request = self.prepare_get(iteration_id, document_id)
        response = self._client._prepared_request(request)
        return MetricResult(**response)

